---
title: "R Study Note"
output: html_notebook
---
Ruidi Zhao's R study note. 

# Lab: Introduction to R

## Useful commands
```{r}
getwd()

```
## Basic Calculation
```{r}
5%%2 # Python: %
2^3 # Python: **
```

## Vector
```{r}
x <- c(1,2,3,4)
y <- c(3,4,5,6)
```

`ls()` is used to look at a list of all of the objects <br>
`rm()` is used to delete any that we don't wat
```{r}
ls() 
rm(x, y) 
ls()
```
```{r}
rm(list=ls()) # remove everything at once
```

## List
```{r}
x <- list(1:3, TRUE, 'Hello', list(1:2, 5))
```

## Matrix
```{r}
x = matrix(data = c(1,2,3,4), nrow = 2, ncol = 2)
x
```

`byrow`的话就是按照row的方向排element
```{r}
matrix(c(1,2,3,4), 2, 2, byrow = TRUE)
```

## DataFrame
```{r}
books <- data.frame(author = c("Ripley", 'Cox', 'Snijders', 'Cox'),
                    year = c(1980, 1979, 1999, 2006),
                    publihser = c('Wiley', "Chapman", "Sage", "CUP"))
books
```
## Function
```{r}
setdiff
```

```{r}
args(setdiff) # Get the arguments for function
```
### Writing Functions
```{r}
square = function(x) {
  x^2
}
square(4)
```

```{r}
mean2 <- function(x) {
  n <- length(x)
  sum(x)/n
}
mean2(1:10)
```
### `for()` Loops
```{r}
factorial2 = function(n) {
  out = 1
  
  for (i in 1:n) {
    out = out * i
  }
  
  out
}
factorial2(10)
```
也可以不用在function外面
```{r}
for (name in 1:4) 
  print(name)
```

### Conditional Code
`for()` loop
```{r}
abs2 = function(x) {
  if (x < 0) out = -x
  else out = x
  out
}
abs2(-4)
```
Or you can use `ifelse()`
```{r}
abs3 = function(x) {
  ifelse(x < 0, -x, x)
}
abs3(2)
abs3(-3)
```

`while()` loops
```{r}
isPrime = function(n){
  i = 2
  if (n < 2) return(FALSE)
  
  while (i < sqrt(n)) {
    if (n%%i == 0) return(FALSE)
    i = i + 1
  }
  return(TRUE) # 注意return后面一定要加上括号
}
isPrime(10)
isPrime(37)
```
### Recursion
```{r}
fib = function(n) {
  if (n<2) return(1)
  else return(fib(n-1) + fib(n-2))
}
fib(10) # 斐波那契数列
```
### `apply()`
If we want to perform a function on every row or column in a matrix (or array), we can use the `apply()` function. The syntax is apply(x, d, f), which will apply the function f to each of the dth dimension of x.If d = 1 this corresponds to rows, and d = 2 to the columns of a matrix. 这个d不就跟python的axis差不多？
```{r}
A = cbind(1:10, (1:10)^2, (1:10)^3)
apply(A, 2, sums) # calculate the sum of all columns
```
It will also work for the matrix-like objects, such as data frames.
```{r}
library(MASS)
apply(hills, 2, mean)
apply(hills, 2, sd)
```

## Random Variables
```{r}
# set.seed(0)
# So that you can reproduce the result

x = rnorm(50,mean = 0, sd = 1)
y = x + rnorm(50, mean = 50, sd = 0.1)
cor(x, y) # Get the correlation between x and y 
var(x)
sd(x)
```
For the particular task of sums or means of rows or columns in a matrix, R contains special functions `rowSums()`, `colSums()`, `rowMeans()`, `colMeans()`. These are all much faster than the equivalent `apply()` commands. 
### `sapply()` and `lapply()`
`lapply()`: use if we want to apply a function to every entry in a list of vector, the syntax is `lapply(vector/list, function)`.
```{r}
mu = c(-2, -1, 0, 1, 2)
out = lapply(mu, function(x) rnorm(100, mean = x))
lapply(out, mean)
```
If we want the result to be a vector
```{r}
sapply(out, mean) #除了这个sapply和lapply都是一样的
```

### `replicate()`
Sometimes we wish to repeat exactly the same operation multiple times, without having a different input (this is typically used in conjunction with the generation of random numbers)
```{r}
out = replicate(20, rnorm(100), simplify = FALSE)
# out is a list of 20 independent data sets, each consisting of 100 standard normal random variables
```
### `tapply()`
Evaluate a function on data in a vector of list which are *grouped* according to the levels of some other factor. For example, 
```{r}
library(MASS)
head(genotype)
```
```{r}
with(genotype, tapply(Wt, Mother, mean))
# group according to the value of Mother
# with(genotype, tapply(Wt, Mother, summary))
```
It is also possible to provide more than one grouping in the form of a list of data frame, in which case the data are broken down by both:
```{r}
tapply(genotype$Wt, genotype[,1:2], mean)
```
### `mapply()`
Sometimes it may be useful to apply a function of several arguments repeatedly, where more than one argument can change. 
```{r}
mapply(seq, from = c(1,4,-3), to = c(2,9,0), by = 0.5)
# 1, 2
# 4, 9
# -3, 0
```
## Arrays and Tables
```{r}
occupationalStatus
# 如果用dataframe表示的话就是3498行，所以可以用这种 "contingency table"（难道不是pivot table吗？）
```
### Higher Dimensions
Arrays are defined much like matrices, with a call to the `array()` command. 
```{r}
arr = array(1:24, dim = c(2,3,4))
# di就是dimension，所以这边是define了一个2*3*4的array
# 所以就是2行3列，然后有4个这样的东西？
arr
```
```{r}
dim(arr)
```
Note that a 2-dimensional array is identical to a matrix. Arrays can be subsetted and modified in exactly the same way as a matrix, only using the appropriate number of co-ordinates:
```{r}
arr[1,2,3]
# 1 行 2 列 第三个东西
```
```{r}
arr[,2,]
```
### Tables
```{r}
library(MASS)
head(cabbages)
```
```{r}
table(cabbages$Date)
# 懂了就是table相当于value_counts() in Python
```
```{r}
table(cabbages[,1:2])
```
### Binning the Data
Discretization
```{r}
# Discretization: group data together into intervals
head(Nile)
bins = c(0, seq(from = 700, to=1300, by=100), Inf) # Inf 就是infinite
bins
```
```{r}
disNile = cut(Nile, bins)
head(disNile)
```
```{r}
table(disNile)
```
```{r}
# you can adjust the lable
disNile = cut(Nile, bins, labels = bins[-9])
table(disNile)
```
## Strings
You can send a string to the screen using the `cat()` function.
```{r}
cat("hello")
"hello" # 如果直接写的话就会有双引号
```

## Graphics
The `plot()` function is the primary way to plot data in R. 
```{r}
x = rnorm(100)
y = rnorm(100)
plot(x, y, xlab = 'x-axis', ylab = 'y-axis', main = 'Plot of X vs Y')
```

save the graph
```{r}
pdf('Figure.pdf') # save it as pdf
# jpeg('Figure.jpeg') # save it as jpeg
plot(x, y, col = 'green')
dev.off() # Tell R that we are done creating the plot
```
Create contour plot with `contour()`, it takes three arguments:
1. A vector of the x values (the first dimension)
2. A vector of the y values (the second dimension), and 
3. A matrix whose elements correspond to the z value (the third dimension) for each pair of (x, y) corrdinates

```{r}
x = seq(1, 10) # or x = 1:10
y = x
f = outer(x, y, function(x, y)cos(y)/(1 + x^2))
contour(x, y, f)
```
Heatmap 
```{r}
image(x, y, f)
```
Use `persp()`
```{r}
persp(x, y, f, theta = 30, phi = 20)
# Theta and phi control the angles at which the plot is viewed
```
## Indexing Data
```{r}
A = matrix(1:16, 4, 4)
A
A[2,3]
```
```{r}
A[c(1, 3), c(2, 4)] # Select multiple row and column
A[1:3, 2:4]
A[, 1:2]
A[1:2, ]
A[-2, ] # '-' means except
dim(A) # The dimension of A, 就是python里的shape?
```
## Loading Data
For most analyses, the first step involves importing a data set into R. 
```{r}
# Auto = read.table('Auto.data', header = T, na.strings = '?')
# dim(Auto) # return the dimension
# Auto = na.omit(Auto) # remove rows with NA
# names(Auto) # Check the variable names
```

Generate some plot
```{r}
# plot(Auto$, Auto$)
# # 或者不使用$
# attach(Auto)
# plot(column1, column2) # scatter plot if two numerical
# hist(column1, col = 2) # histogram
# pairs(Auto) # scatter plot matrix 
```
Quantitative to Categorical with `as.factor()`
```{r}
# cylinders = as.factor(cylinders)
```
`summary()` function produces a numerical summary of each variable in a particular data set
```{r}
# summary(Auto)
```

## Record history
```{r}
savehistory() # save a record of all of the commands in the most recent session
loadhistory() # load the history next time we use R
```

# Lab: Linear Regression
```{r}
library(MASS)
library(ISLR)
names(Boston)
lm.fit = lm(medv~lstat, data = Boston) # lm: least square linear regression model
                        # lm(y~x, data)
```
Get information about our linear regression model
```{r}
lm.fit
summary(lm.fit)
names(lm.fit) # what kind of info are stored?
coef(lm.fit) # get the coefficient; or lm.fit$coefficients
```
Next, we examine some diagnostic plots
```{r}
par(mfrow = c(2, 2)) # split the screen into 4 parts
plot(lm.fit)
```
```{r}
plot(predict(lm.fit), residuals(lm.fit))
plot(predict(lm.fit), rstudent(lm.fit))
```

Compute the leverage statistics
```{r}
plot(hatvalues(lm.fit))
which.max(hatvalues(lm.fit)) # == python idxmax()
```
## Multiple Linear Regression
```{r}
lm.fit = lm(medv~lstat + age, data = Boston) # 如果是multiple的话格式是lm(y~x1+x2+x3)
summary(lm.fit)
```
If we want to use all variables as the X variables
```{r}
lm.fit = lm(medv~., data = Boston) # use this short-hand!
summary(lm.fit)
```
What if we would like to perform a regression using all of the variables but one?
```{r}
lm.fit1 = lm(medv~.-age, data = Boston) # 懂了！就是.-age就好了
summary(lm.fit1)
```
Alternatively, the `update()` function can be used
```{r}
lm.fit1 = update(lm.fit, ~.-age) #！！
```

## Interaction Terms
```{r}
summary(lm(medv~lstat*age, data = Boston))
# lstat*age is the short-hand for: lstat + age + lstat: age
```
## Non-linear Transformations of the Predictors
```{r}
lm.fit2 = lm(medv~lstat + I(lstat^2), data = Boston)
summary(lm.fit2)
```
The near-zero p-value associated with the quadratic term suggests that it leads to an improved model. We use `anova()` function to further quantify the extent to which the quadratic fit is superior to the linear fit. 
```{r}
lm.fit = lm(medv~lstat, data = Boston)
anova(lm.fit, lm.fit2)
```
The `anova()` function performs a hypothesis test comparing the two models. The null hypothesis is that the two models fir the data equally well, and the alternative hypothesis is that the full model is superior. Here, the p-value is near zero, so we favor the alternative hypothesis. 
```{r}
par(mfrow = c(2, 2))
plot(lm.fit2)
# There is little discernible pattern in the residuals
```
We can also do a fifth-order polynomial fit:
```{r}
lm.fit5 = lm(medv~poly(lstat, 5), data = Boston)
summary(lm.fit5)
```
Or a log transformation
```{r}
summary(lm(medv~log(rm), data = Boston))
```
## Qualitative Predictors
```{r}
names(Carseats) # examine the Carseats data
# Try to predict Sales
```

```{r}
lm.fit = lm(Sales~.+Income:Advertising+Price:Age, data = Carseats)
# 如果有Categorical data, R 自动 dummy variable
summary(lm.fit)
```
The `contrasts()` function returns the coding that R uses for the dummy variables
```{r}
contrasts(Carseats$ShelveLoc)
# ShelveLocGood & ShelveLocMeidum
# 注意，自动drop_first = True
```

```{r}
LoadLibraries = function() {
  library(ISIR)
  library(MASS)
  print("The libraries have been loaded.")
}
```

# Lab: Logistic Regression, LDA, QDA, and KNN
```{r}
library(ISLR)
names(Smarket)
```
The `cor()` function produces a matrix that contains all of the pairwise correlations among the predictors in a data set. 
```{r}
cor(Smarket[,-9]) # R不像Python一样会自动过滤掉categorical，所以要手动减掉
```

```{r}
attach(Smarket)
plot(Volume)
# We can see that that the Volume is increasing over time
```

## Logistic Regression
`glm()` function *generalized linear models*, a class of models that includes logistic regression.
```{r}
glm.fit = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Smarket, family = binomial)
# family = binoial, tell R to run a logistic regression
summary(glm.fit)
```
```{r}
coef(glm.fit)
```
```{r}
summary(glm.fit)$coef
```
```{r}
glm.probs = predict(glm.fit, type = "response")
# type = "response", the output is P(Y = 1|X)
glm.probs[1:10] # if no X data is passed, automatically use X_train
```
```{r}
contrasts(Direction)
```
```{r}
glm.pred = rep("Down", 1250)
glm.pred[glm.probs > 0.5] = "Up"
```
```{r}
table(glm.pred, Direction)
mean(glm.pred == Direction) # Get classification correct rate
```
```{r}
train = (Year < 2005)
Smarket.2005 = Smarket[!train, ]
dim(Smarket.2005)
# Get the data after 2005.
```
```{r}
glm.fits = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Smarket, family = binomial,
               subset = train) #只用2005之前的data train model
glm.probs = predict(glm.fits, Smarket.2005, type = "response")
```

```{r}
Direction.2005 = Direction[!train]
glm.pred = rep("Down", 252)
glm.pred[glm.probs>0.5] = "Up"
table(glm.pred, Direction.2005)
mean(glm.pred == Direction.2005)
```
Refit the model with only `Lag1` and `Lag2`
```{r}
glm.fit2 = glm(Direction~Lag1+Lag2, data = Smarket, family = binomial, subset = train)
glm.prob = predict(glm.fit2, Smarket.2005, type = "response")
glm.pred = rep("Down", 252)
glm.pred[glm.prob > 0.5] = "Up"
table(glm.pred, Direction.2005)
mean(glm.pred == Direction.2005)
```
如果想predict on specific value
```{r}
predict(glm.fit2, newdata = data.frame(Lag1 = c(1.2, 1.5), Lag2 = c(1.1, -0.8)),
        type = "response")
```

## Linear Discriminant Analysis
