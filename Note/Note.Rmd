---
title: "R Study Note"
output: html_notebook
---
Ruidi Zhao's R study note. 

# Lab: Introduction to R
```{r}
x <- c(1,2,3,4)
y <- c(3,4,5,6)
```

`ls()` is used to look at a list of all of the objects <br>
`rm()` is used to delete any that we don't wat
```{r}
ls() 
rm(x, y) 
ls()
```
```{r}
rm(list=ls()) # remove everything at once
```

## Matrix
```{r}
x = matrix(data = c(1,2,3,4), nrow = 2, ncol = 2)
x
```

`byrow`的话就是按照row的方向排element
```{r}
matrix(c(1,2,3,4), 2, 2, byrow = TRUE)
```

## Random Variables
```{r}
# set.seed(0)
# So that you can reproduce the result

x = rnorm(50,mean = 0, sd = 1)
y = x + rnorm(50, mean = 50, sd = 0.1)
cor(x, y) # Get the correlation between x and y 
var(x)
sd(x)
```

## Graphics
The `plot()` function is the primary way to plot data in R. 
```{r}
x = rnorm(100)
y = rnorm(100)
plot(x, y, xlab = 'x-axis', ylab = 'y-axis', main = 'Plot of X vs Y')
```

save the graph
```{r}
pdf('Figure.pdf') # save it as pdf
# jpeg('Figure.jpeg') # save it as jpeg
plot(x, y, col = 'green')
dev.off() # Tell R that we are done creating the plot
```
Create contour plot with `contour()`, it takes three arguments:
1. A vector of the x values (the first dimension)
2. A vector of the y values (the second dimension), and 
3. A matrix whose elements correspond to the z value (the third dimension) for each pair of (x, y) corrdinates

```{r}
x = seq(1, 10) # or x = 1:10
y = x
f = outer(x, y, function(x, y)cos(y)/(1 + x^2))
contour(x, y, f)
```
Heatmap 
```{r}
image(x, y, f)
```
Use `persp()`
```{r}
persp(x, y, f, theta = 30, phi = 20)
# Theta and phi control the angles at which the plot is viewed
```
## Indexing Data
```{r}
A = matrix(1:16, 4, 4)
A
A[2,3]
```
```{r}
A[c(1, 3), c(2, 4)] # Select multiple row and column
A[1:3, 2:4]
A[, 1:2]
A[1:2, ]
A[-2, ] # '-' means except
dim(A) # The dimension of A, 就是python里的shape?
```
## Loading Data
For most analyses, the first step involves importing a data set into R. 
```{r}
# Auto = read.table('Auto.data', header = T, na.strings = '?')
# dim(Auto) # return the dimension
# Auto = na.omit(Auto) # remove rows with NA
# names(Auto) # Check the variable names
```

Generate some plot
```{r}
# plot(Auto$, Auto$)
# # 或者不使用$
# attach(Auto)
# plot(column1, column2) # scatter plot if two numerical
# hist(column1, col = 2) # histogram
# pairs(Auto) # scatter plot matrix 
```
Quantitative to Categorical with `as.factor()`
```{r}
# cylinders = as.factor(cylinders)
```
`summary()` function produces a numerical summary of each variable in a particular data set
```{r}
# summary(Auto)
```

## Record history
```{r}
savehistory() # save a record of all of the commands in the most recent session
loadhistory() # load the history next time we use R
```

# Lab: Linear Regression
```{r}
library(MASS)
library(ISLR)
names(Boston)
lm.fit = lm(medv~lstat, data = Boston) # lm: least square linear regression model
                        # lm(y~x, data)
```
Get information about our linear regression model
```{r}
lm.fit
summary(lm.fit)
names(lm.fit) # what kind of info are stored?
coef(lm.fit) # get the coefficient; or lm.fit$coefficients
```
Next, we examine some diagnostic plots
```{r}
par(mfrow = c(2, 2)) # split the screen into 4 parts
plot(lm.fit)
```
```{r}
plot(predict(lm.fit), residuals(lm.fit))
plot(predict(lm.fit), rstudent(lm.fit))
```

Compute the leverage statistics
```{r}
plot(hatvalues(lm.fit))
which.max(hatvalues(lm.fit)) # == python idxmax()
```
## Multiple Linear Regression
```{r}
lm.fit = lm(medv~lstat + age, data = Boston) # 如果是multiple的话格式是lm(y~x1+x2+x3)
summary(lm.fit)
```
If we want to use all variables as the X variables
```{r}
lm.fit = lm(medv~., data = Boston) # use this short-hand!
summary(lm.fit)
```
What if we would like to perform a regression using all of the variables but one?
```{r}
lm.fit1 = lm(medv~.-age, data = Boston) # 懂了！就是.-age就好了
summary(lm.fit1)
```
Alternatively, the `update()` function can be used
```{r}
lm.fit1 = update(lm.fit, ~.-age) #！！
```

## Interaction Terms
```{r}
summary(lm(medv~lstat*age, data = Boston))
# lstat*age is the short-hand for: lstat + age + lstat: age
```
## Non-linear Transformations of the Predictors
```{r}
lm.fit2 = lm(medv~lstat + I(lstat^2), data = Boston)
summary(lm.fit2)
```
The near-zero p-value associated with the quadratic term suggests that it leads to an improved model. We use `anova()` function to further quantify the extent to which the quadratic fit is superior to the linear fit. 
```{r}
lm.fit = lm(medv~lstat, data = Boston)
anova(lm.fit, lm.fit2)
```
The `anova()` function performs a hypothesis test comparing the two models. The null hypothesis is that the two models fir the data equally well, and the alternative hypothesis is that the full model is superior. Here, the p-value is near zero, so we favor the alternative hypothesis. 
```{r}
par(mfrow = c(2, 2))
plot(lm.fit2)
# There is little discernible pattern in the residuals
```
We can also do a fifth-order polynomial fit:
```{r}
lm.fit5 = lm(medv~poly(lstat, 5), data = Boston)
summary(lm.fit5)
```
Or a log transformation
```{r}
summary(lm(medv~log(rm), data = Boston))
```
## Qualitative Predictors


